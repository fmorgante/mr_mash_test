---
title: "Prediction accuracy"
author: "Fabio Morgante"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  workflowr::wflow_html:
    toc: false
editor_options:
  chunk_output_type: console
---

```{r set opts}
options(stringsAsFactors = FALSE)

accuracy <- function(Y, Yhat) {
  bias <- rep(NA, ncol(Y))
  r2 <- rep(NA, ncol(Y))
  mse <- rep(NA, ncol(Y))
  
  for(i in 1:ncol(Y)){
    fit  <- lm(Y[, i] ~ Yhat[, i])
    bias[i] <- coef(fit)[2] 
    r2[i] <- summary(fit)$r.squared
    mse[i] <- mean((Y[, i] - Yhat[, i])^2)
  }
  
  return(list(bias=bias, r2=r2, mse=mse))
}
```

##Simulation 1 -- Shared effects, independent variables

```{r load data 1}
dat1 <- readRDS("output/fit_mr_mash_n600_p1000_p_caus50_r5_pve0.5_sigmaoffdiag1_sigmascale0.8_gammaoffdiag0_gammascale0.8_Voffdiag0.2_Vscale0_updatew0TRUE_updatew0TRUE_updatew0methodmixsqp_updateVTRUE.rds")
n1 <- dat1$params$n
p1 <- dat1$params$p
p_causal1 <- dat1$params$p_causal
r1 <- dat1$params$r
pve1 <- dat1$params$pve
prop_testset1 <- dat1$params$prop_testset
B1 <- dat1$inputs$B
V1 <- dat1$inputs$V
Sigma1 <- dat1$inputs$Sigma
Gamma1 <- dat1$inputs$Gamma
Ytrain1 <- dat1$Ytrain
Ytest1 <- dat1$Ytest
mu11 <- dat1$fit$mu1
fitted1 <- dat1$fit$fitted
Yhat_test1 <- dat1$Yhat_test
```

The results below are based on simulation with `r n1` samples, `r p1` variables of which `r p_causal1` were causal, `r r1` responses with a per-response proportion of variance explained (PVE) of `r pve1`. Variables, X, were drawn from MVN(0, Gamma), causal effects, B, were drawn from MVN(0, Sigma). The responses, Y, were drawn from MN(XB, I, V).

```{r disp corrs 1}
cat("Gamma (First 5 elements)")
Gamma1[1:5, 1:5]

cat("Sigma")
Sigma1

cat("V")
V1
```

mr.mash was fitted to the training data (`r (1-prop_testset1)*100`% of the data) updating V and updating the prior weights using mixSQP. Then, responses were predicted on the test data (`r prop_testset1*100`% of the data).

In the plots below, each color/symbol defines a diffrent response.

Here, we compare the estimated effects with the true effects. 
```{r effects 1, fig.height=12, fig.width=15}
plot(B1[, 1], mu11[, 1], xlab="True effects", ylab="Estimated effects", main="True vs Estimated Effects", pch=1, cex.lab=1.5, cex.axis=1.5)
points(B1[, 2], mu11[, 2], col="blue", pch=2)
points(B1[, 3], mu11[, 3], col="red", pch=3)
points(B1[, 4], mu11[, 4], col="green", pch=4)
points(B1[, 5], mu11[, 5], col="yellow", pch=8)
```

Then, we compare the predicted responses with the true responses in the training data (left panel) and test data (right panel).
```{r predict 1, fig.height=12, fig.width=15}
par(mfrow=c(1,2))
plot(Ytrain1[, 1], fitted1[, 1], xlab="True responses", ylab="Fitted values", main="True vs Fitted values \nTraining data", pch=1, cex.lab=1.5, cex.axis=1.5)
points(Ytrain1[, 2], fitted1[, 2], col="blue", pch=2)
points(Ytrain1[, 3], fitted1[, 3], col="red", pch=3)
points(Ytrain1[, 4], fitted1[, 4], col="green", pch=4)
points(Ytrain1[, 5], fitted1[, 5], col="yellow", pch=8)
abline(0, 1)

plot(Ytrain1[, 1], fitted1[, 1], xlab="True responses", ylab="Predicted responses", main="True vs Predicted Responses \nTest data", pch=1, cex.lab=1.5, cex.axis=1.5)
points(Ytest1[, 2], Yhat_test1[, 2], col="blue", pch=2)
points(Ytest1[, 3], Yhat_test1[, 3], col="red", pch=3)
points(Ytest1[, 4], Yhat_test1[, 4], col="green", pch=4)
points(Ytest1[, 5], Yhat_test1[, 5], col="yellow", pch=8)
abline(0, 1)
par(mfrow=c(1,1))

r2_train1 <- round(accuracy(Ytrain1, fitted1)$r2, 4)
r2_test1 <- round(accuracy(Ytest1, Yhat_test1)$r2, 4)
bias_train1 <- round(accuracy(Ytrain1, fitted1)$bias, 4)
bias_test1 <- round(accuracy(Ytest1, Yhat_test1)$bias, 4)
mse_train1 <- round(accuracy(Ytrain1, fitted1)$mse, 4)
mse_test1 <- round(accuracy(Ytest1, Yhat_test1)$mse, 4)

acc1 <- rbind(r2_train1, r2_test1, bias_train1, bias_test1, mse_train1, mse_test1)
colnames(acc1) <- paste0("Y", seq(1, r1))
part_metric1 <- c("Training data r2", "Test data r2", "Training data bias", "Test data bias" , "Training data MSE" , "Test data MSE")
res1 <- data.frame(part_metric1, acc1)
colnames(res1)[1] <- c("Partition_metric")
rownames(res1) <- NULL
print(res1)
```


##Simulation 2 -- Independent effects, independent variables

```{r load data 2}
dat2 <- readRDS("output/fit_mr_mash_n600_p1000_p_caus50_r5_pve0.5_sigmaoffdiag0_sigmascale0.8_gammaoffdiag0_gammascale0.8_Voffdiag0.2_Vscale0_updatew0TRUE_updatew0TRUE_updatew0methodmixsqp_updateVTRUE.rds")
n2 <- dat2$params$n
p2 <- dat2$params$p
p_causal2 <- dat2$params$p_causal
r2 <- dat2$params$r
pve2 <- dat2$params$pve
prop_testset2 <- dat2$params$prop_testset
B2 <- dat2$inputs$B
V2 <- dat2$inputs$V
Sigma2 <- dat2$inputs$Sigma
Gamma2 <- dat2$inputs$Gamma
Ytrain2 <- dat2$Ytrain
Ytest2 <- dat2$Ytest
mu12 <- dat2$fit$mu1
fitted2 <- dat2$fit$fitted
Yhat_test2 <- dat2$Yhat_test
```

The results below are based on simulation with `r n2` samples, `r p2` variables of which `r p_causal2` were causal, `r r2` responses with a per-response proportion of variance explained (PVE) of `r pve2`. Variables, X, were drawn from MVN(0, Gamma), causal effects, B, were drawn from MVN(0, Sigma). The responses, Y, were drawn from MN(XB, I, V).

```{r disp corrs 2}
cat("Gamma (First 5 elements)")
Gamma2[1:5, 1:5]

cat("Sigma")
Sigma2

cat("V")
V2
```

mr.mash was fitted to the training data (`r (1-prop_testset2)*100`% of the data) updating V and updating the prior weights using mixSQP. Then, responses were predicted on the test data (`r prop_testset2*100`% of the data).

In the plots below, each color/symbol defines a diffrent response.

Here, we compare the estimated effects with the true effects. 
```{r effects 2, fig.height=12, fig.width=15}
plot(B2[, 1], mu12[, 1], xlab="True effects", ylab="Estimated effects", main="True vs Estimated Effects", pch=1, cex.lab=1.5, cex.axis=1.5)
points(B2[, 2], mu12[, 2], col="blue", pch=2)
points(B2[, 3], mu12[, 3], col="red", pch=3)
points(B2[, 4], mu12[, 4], col="green", pch=4)
points(B2[, 5], mu12[, 5], col="yellow", pch=8)
```

Then, we compare the predicted responses with the true responses in the training data (left panel) and test data (right panel).
```{r predict 2, fig.height=12, fig.width=15}
par(mfrow=c(1,2))
plot(Ytrain2[, 1], fitted2[, 1], xlab="True responses", ylab="Fitted values", main="True vs Fitted values \nTraining data", pch=1, cex.lab=1.5, cex.axis=1.5)
points(Ytrain2[, 2], fitted2[, 2], col="blue", pch=2)
points(Ytrain2[, 3], fitted2[, 3], col="red", pch=3)
points(Ytrain2[, 4], fitted2[, 4], col="green", pch=4)
points(Ytrain2[, 5], fitted2[, 5], col="yellow", pch=8)
abline(0, 1)

plot(Ytrain2[, 1], fitted2[, 1], xlab="True responses", ylab="Predicted responses", main="True vs Predicted Responses \nTest data", pch=1, cex.lab=1.5, cex.axis=1.5)
points(Ytest2[, 2], Yhat_test2[, 2], col="blue", pch=2)
points(Ytest2[, 3], Yhat_test2[, 3], col="red", pch=3)
points(Ytest2[, 4], Yhat_test2[, 4], col="green", pch=4)
points(Ytest2[, 5], Yhat_test2[, 5], col="yellow", pch=8)
abline(0, 1)
par(mfrow=c(1,1))

r2_train2 <- round(accuracy(Ytrain2, fitted2)$r2, 4)
r2_test2 <- round(accuracy(Ytest2, Yhat_test2)$r2, 4)
bias_train2 <- round(accuracy(Ytrain2, fitted2)$bias, 4)
bias_test2 <- round(accuracy(Ytest2, Yhat_test2)$bias, 4)
mse_train2 <- round(accuracy(Ytrain2, fitted2)$mse, 4)
mse_test2 <- round(accuracy(Ytest2, Yhat_test2)$mse, 4)

acc2 <- rbind(r2_train2, r2_test2, bias_train2, bias_test2, mse_train2, mse_test2)
colnames(acc2) <- paste0("Y", seq(1, r2))
part_metric2 <- c("Training data r2", "Test data r2", "Training data bias", "Test data bias" , "Training data MSE" , "Test data MSE")
res2 <- data.frame(part_metric2, acc2)
colnames(res2)[1] <- c("Partition_metric")
rownames(res2) <- NULL
print(res2)
```


##Simulation 3 -- Shared effects, correlated variables

```{r load data 3}
dat3 <- readRDS("output/fit_mr_mash_n600_p1000_p_caus50_r5_pve0.5_sigmaoffdiag1_sigmascale0.8_gammaoffdiag0.5_gammascale0.8_Voffdiag0.2_Vscale0_updatew0TRUE_updatew0TRUE_updatew0methodmixsqp_updateVTRUE.rds")
n3 <- dat3$params$n
p3 <- dat3$params$p
p_causal3 <- dat3$params$p_causal
r3 <- dat3$params$r
pve3 <- dat3$params$pve
prop_testset3 <- dat3$params$prop_testset
B3 <- dat3$inputs$B
V3 <- dat3$inputs$V
Sigma3 <- dat3$inputs$Sigma
Gamma3 <- dat3$inputs$Gamma
Ytrain3 <- dat3$Ytrain
Ytest3 <- dat3$Ytest
mu13 <- dat3$fit$mu1
fitted3 <- dat3$fit$fitted
Yhat_test3 <- dat3$Yhat_test
```

The results below are based on simulation with `r n3` samples, `r p3` variables of which `r p_causal3` were causal, `r r3` responses with a per-response proportion of variance explained (PVE) of `r pve3`. Variables, X, were drawn from MVN(0, Gamma), causal effects, B, were drawn from MVN(0, Sigma). The responses, Y, were drawn from MN(XB, I, V).

```{r disp corrs 3}
cat("Gamma (First 5 elements)")
Gamma3[1:5, 1:5]

cat("Sigma")
Sigma3

cat("V")
V3
```

mr.mash was fitted to the training data (`r (1-prop_testset3)*100`% of the data) updating V and updating the prior weights using mixSQP. Then, responses were predicted on the test data (`r prop_testset3*100`% of the data).

In the plots below, each color/symbol defines a diffrent response.

Here, we compare the estimated effects with the true effects. 
```{r effects 3, fig.height=12, fig.width=15}
plot(B3[, 1], mu13[, 1], xlab="True effects", ylab="Estimated effects", main="True vs Estimated Effects", pch=1, cex.lab=1.5, cex.axis=1.5)
points(B3[, 2], mu13[, 2], col="blue", pch=2)
points(B3[, 3], mu13[, 3], col="red", pch=3)
points(B3[, 4], mu13[, 4], col="green", pch=4)
points(B3[, 5], mu13[, 5], col="yellow", pch=8)
```

Then, we compare the predicted responses with the true responses in the training data (left panel) and test data (right panel).
```{r predict 3, fig.height=12, fig.width=15}
par(mfrow=c(1,2))
plot(Ytrain3[, 1], fitted3[, 1], xlab="True responses", ylab="Fitted values", main="True vs Fitted values \nTraining data", pch=1, cex.lab=1.5, cex.axis=1.5)
points(Ytrain3[, 2], fitted3[, 2], col="blue", pch=2)
points(Ytrain3[, 3], fitted3[, 3], col="red", pch=3)
points(Ytrain3[, 4], fitted3[, 4], col="green", pch=4)
points(Ytrain3[, 5], fitted3[, 5], col="yellow", pch=8)
abline(0, 1)

plot(Ytrain3[, 1], fitted3[, 1], xlab="True responses", ylab="Predicted responses", main="True vs Predicted Responses \nTest data", pch=1, cex.lab=1.5, cex.axis=1.5)
points(Ytest3[, 2], Yhat_test3[, 2], col="blue", pch=2)
points(Ytest3[, 3], Yhat_test3[, 3], col="red", pch=3)
points(Ytest3[, 4], Yhat_test3[, 4], col="green", pch=4)
points(Ytest3[, 5], Yhat_test3[, 5], col="yellow", pch=8)
abline(0, 1)
par(mfrow=c(1,1))

r2_train3 <- round(accuracy(Ytrain3, fitted3)$r2, 4)
r2_test3 <- round(accuracy(Ytest3, Yhat_test3)$r2, 4)
bias_train3 <- round(accuracy(Ytrain3, fitted3)$bias, 4)
bias_test3 <- round(accuracy(Ytest3, Yhat_test3)$bias, 4)
mse_train3 <- round(accuracy(Ytrain3, fitted3)$mse, 4)
mse_test3 <- round(accuracy(Ytest3, Yhat_test3)$mse, 4)

acc3 <- rbind(r2_train3, r2_test3, bias_train3, bias_test3, mse_train3, mse_test3)
colnames(acc3) <- paste0("Y", seq(1, r3))
part_metric3 <- c("Training data r2", "Test data r2", "Training data bias", "Test data bias" , "Training data MSE" , "Test data MSE")
res3 <- data.frame(part_metric3, acc3)
colnames(res3)[1] <- c("Partition_metric")
rownames(res3) <- NULL
print(res3)
```